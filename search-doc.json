[{"title":"Hello world!","type":0,"sectionRef":"#","url":"blog/2020/12/12/hello-world","content":"tl;dr (1) decomissioned a cluster, (2) got a bunch of GPUs for maching learning, (3) launched a cluster, and (4) new and improved documentation. 2020 has definitely been an eventful year but here on Team Hyak we've been trying to make the best of a bad situation (lemons out of lemonade and such). This year saw the decomissioning of the 1st generation Hyak cluster, ikt, and the soft launch of our 3rd generation Hyak cluster, klone. Our partnership with the Allen School and other departments across campus has enabled an explosion in on-campus GPU capacity for the current 2nd generation Hyak cluster, mox. This is all very exciting, machine learning is only going to get bigger. We realize whether you do your research on your laptop, Hyak, or the cloud that at the end of the day it's all just a computer and what matters is what you can actually do with it. Therefore, we are placing more emphasis on new and improved documentation (this website) and will be doing more regular research tutorials on Hyak throughout the coming year. We hope you have weathered the adversity 2020 brought upon everyone. It has been a tough year for sure, but may your 2021 be brighter and have improvements in store. The Hyak Team has lots of efforts in the works to benefit supporting your research and they will hit full stride in the coming year. This is one improvement we can all look forward to in 2021.","keywords":""},{"title":"scRNA-seq","type":0,"sectionRef":"#","url":"blog/2020/12/14/scrna-seq","content":"Over the past year we've done a bunch of outreach to labs within the genomics community here at the UW. Given my research background it's where I feel most comfortable and this type of research is underrepresented on the cluster. Given where the field is going it's inconceivable they aren't using Hyak or HPC in general! Those lab closet clusters and under bench servers gotta go, there is a better way and we'll show you how to do some scRNA-seq today ðŸ™‚ TODO","keywords":""},{"title":"Start Here","type":0,"sectionRef":"#","url":"docs/","content":"Welcome!","keywords":""},{"title":"Account Activation","type":0,"sectionRef":"#","url":"docs/account-activation","content":"Your UW Net ID has been enabled for access to the Hyak system. You must now subscribe to the service. After you subscribe, it may take up to an hour for your account to be fully provisioned. Go to uwnetid.washington.eduClick the \"Computing Services\" link on the leftClick the \"Hyak Server\" check box in the \"Inactive Services\" sectionClick the \"Subscribe >\" button at the bottom of the pageRead the notice and click the \"Finish\" button UW policy is that all services (of which HYAK is one) require 2 factor authentication (2FA) by default as a security posture. important You need 2FA to log onto any HYAK cluster. You can use a personal device (e.g., phone, tablet) or a land line as your two-factor token, please go to this 2FA page and ensure you have it enabled and configured. If you wish to use an older style single purpose token, visit this page and ask for a security token. tip Sign up for the HYAK mailing list here and stay up to date on system news! The HYAK mailing list is low volume (average < 1 email per month) and provides critical announcements in the event of a service issue, maintenance, or other updates.","keywords":""},{"title":"Account Creation","type":0,"sectionRef":"#","url":"docs/account-creation","content":"","keywords":""},{"title":"I have a PI and the PI contributed HYAK nodes.","type":1,"pageTitle":"Account Creation","url":"docs/account-creation#i-have-a-pi-and-the-pi-contributed-hyak-nodes","content":"Your PI can create a HYAK account for you by virtue of adding you to their group. Refer to the previous section about adding users to a group. "},{"title":"I have a PI and we have no HYAK nodes.","type":1,"pageTitle":"Account Creation","url":"docs/account-creation#i-have-a-pi-and-we-have-no-hyak-nodes","content":"You need to email us to get a free tier account. Please provide your UW netID. If your PI has purchased HYAK storage you will need them to follow the step above to be added to the group and have access to your shared data on the cluster after you're able to log in. "},{"title":"I'm a UW student and I have no PI.","type":1,"pageTitle":"Account Creation","url":"docs/account-creation#im-a-uw-student-and-i-have-no-pi","content":"If you are a UW student tech fee (STF) paying student, which is almost every UW student, you are eligible to join the Research Computing Club (RCC). The RCC has a pool of nodes on every HYAK cluster for you to use. You can join the RCC and thereby get a Hyak account created through them here and use their resource capacity on the cluster. Once your account is created you can resume to the next page with instructions on how to activate. "},{"title":"I am an external collaborator or I have no UW netID.","type":1,"pageTitle":"Account Creation","url":"docs/account-creation#i-am-an-external-collaborator-or-i-have-no-uw-netid","content":"Having a UW netID is a pre-requisite for any type of HYAK account creation. If you are an external collaborator of a current HYAK user and need a UW netID you will need to have your UW collaborator sponsor you for a netID. Please have them follow these instructions then once you have your netID, find yourself in one of the previous categories to be added to a group. Once you are added to a group you can resume with account activation on the next page. "},{"title":"Linking Markdown to Docusaurus","type":0,"sectionRef":"#","url":"docs/contribute/link-markdown","content":"","keywords":""},{"title":"Markdown Files","type":1,"pageTitle":"Linking Markdown to Docusaurus","url":"docs/contribute/link-markdown#markdown-files","content":"Basically all Markdown files go in the docs folder Each Markdown file should have at least id and title YAML headers: Copy --- id: some-id # seems like the convention is to separate words with hyphens? title: Some Title --- ...rest of Markdown document...  "},{"title":"Sidebar Configuration","type":1,"pageTitle":"Linking Markdown to Docusaurus","url":"docs/contribute/link-markdown#sidebar-configuration","content":"Add the id of the Markdown document to the correct category/make new category in sidebars.js sidebars.js should have a general structure like: Copy module.exports = { sidebarName: { \"Some Category Name\": [ \"some-id\", \"another-id\", ... ], \"Another Category Name\": [ \"yet-another-id\", { // subcategory declaration type: 'category', label: 'Subcategory Name', items: [ 'subcategory-doc-id', ... ] } \"yet-yet-another-id\" ... ] } }  Full description of possible headers (more info here): id: A unique document id. If this field is not present, the document's id will default to its file name (without the extension). (Please still explicitly include the id though! ) title: The title of your document. If this field is not present, the document's title will default to its id. (Also explicitly include the title too)hide_title: Whether to hide the title at the top of the doc. By default it is false.sidebar_label: The text shown in the document sidebar and in the next/previous button for this document. If this field is not present, the document's sidebar_label will default to its title.custom_edit_url: The URL for editing this document. If this field is not present, the document's edit URL will fall back to editUrl from options fields passed to docusaurus-plugin-content-docs.keywords: Keywords meta tag for the document page, for search engines.description: The description of your document, which will become the <meta name=\"description\" content=\"...\"/> and <meta property=\"og:description\" content=\"...\"/> in <head>, used by search engines. If this field is not present, it will default to the first line of the contents.image: Cover or thumbnail image that will be used when displaying the link to your post. More information about sidebars here. "},{"title":"Scheduling Jobs","type":0,"sectionRef":"#","url":"docs/compute/scheduling-jobs","content":"","keywords":""},{"title":"Interactive Nodes","type":1,"pageTitle":"Scheduling Jobs","url":"docs/compute/scheduling-jobs#interactive-nodes","content":"There are two types of interactive nodes. Compute nodes run computations but cannot connect to the internet. Build nodes are compute nodes that can connect to the Internet to get files and install packages from outside the mox ecosystem. "},{"title":"Obtaining Interactive Nodes","type":1,"pageTitle":"Scheduling Jobs","url":"docs/compute/scheduling-jobs#obtaining-interactive-nodes","content":"To get an interactive compute node with <size> GB of memory in your group partition called <group_name> for <time> hours, use: Copy srun -p <group_name> --time=<time> --mem=<size>G --pty /bin/bash Common acceptable time formats include hours:minutes:seconds, days-hours, and minutes. Example: Copy [linj66@mox2 ~]$ srun -p stf --time=1:00:00 --mem=20G --pty /bin/bash [linj66@n2148 ~]$   To get an interactive compute node with <num_cores> cores, use: Copy srun -p <group_name> -A <group_name> --nodes=1 \\ --ntasks-per-node=<num_cores> --time=<time> \\ --mem=<size>G --pty /bin/bash  To get multiple interactive compute nodes with <num_nodes> as the number of nodes and <cores_per_node> as the number of cores, use: Copy srun -p <group_name> -A <group_name> --nodes=<num_nodes> \\ --ntasks-per-node=<cores_per_node> --time=<time> \\ --mem=<size>G --pty /bin/bash When this command runs, you will automatically enter into a session in one of the allocated nodes. To view the names of all your allocated nodes, use scontrol show hostnames. important If you are using an interactive node to run a parallel application such as Python multiprocessing, MPI, OpenMP etc. then the number given for the --ntasks-per-node option must match the number of processes used by your application.  If your group has an interactive node, use the option -p <group_name>-int like so: Copy srun -p <group_name>-int -A <group_name> --time=<time> --mem=<size>G --pty /bin/bash note --pty /bin/bash must be the last option given in above commandIf you do not obtain a build node with the specified --mem value, try smaller memory values For more details, read the srun man page. "},{"title":"Build Nodes","type":1,"pageTitle":"Scheduling Jobs","url":"docs/compute/scheduling-jobs#build-nodes","content":"Build nodes are allocated from the build group partition. To obtain a build node, execute srun with the option -p build. "},{"title":"Specifying Memory Size","type":1,"pageTitle":"Scheduling Jobs","url":"docs/compute/scheduling-jobs#specifying-memory-size","content":"It is important to use the --mem option to specify the memory allocation; otherwise the Slurm scheduler limits the memory allocation to a default value which is usually quite low. The value given to --mem should be smaller than the memory of the node as the operating system needs some. For 64GB nodes, use --mem=58GFor 128GB nodes, use --mem=120GFor 192GB nodes, use --mem=185GFor 256GB nodes, use --mem=248GFor 384GB nodes, use --mem=374GFor 512GB nodes, use --mem=500GFor 768GB nodes, use --mem=752GFor the knl nodes, use --mem=200G "},{"title":"Slurm Environment Variables","type":1,"pageTitle":"Scheduling Jobs","url":"docs/compute/scheduling-jobs#slurm-environment-variables","content":"When a job scheduled by Slurm begins, it needs to about how it was scheduled, what its working directory is, who submitted the job, the number of nodes and cores allocated to it, etc. This information is passed to Slurm via environment variables. Additionally, these environment variables are also used as default values by programs like mpirun. To view a node's Slurm environment variables, use export | grep SLURM. A comprehensive list of the environment variables Slurm sets for each job can be found at the end of the sbatch man page. "},{"title":"Batch Jobs","type":1,"pageTitle":"Scheduling Jobs","url":"docs/compute/scheduling-jobs#batch-jobs","content":""},{"title":"Single Node Batch Jobs","type":1,"pageTitle":"Scheduling Jobs","url":"docs/compute/scheduling-jobs#single-node-batch-jobs","content":"Below is a slurm script template. Submit a batch job from the mox login node by calling sbatch <script_name>.slurm. <script_name>.slurm Copy !/bin/bash # JOB NAME SBATCH --job-name=<your_job_name> # ALLOCATION DEFINITION # The account and partition options should be the same # except in a few cases (e.g. ckpt queue, genpool queue) SBATCH --account=<group_name> SBATCH --partition=<group_name> # RESOURCES SBATCH --nodes=<num_nodes> # total number of nodes allocated SBATCH --ntasks-per-node=<cores_per_node> # cores per node # WALL TIME # Do not specify a wall time significantly more than your job needs # Common acceptable time formats: # hours:minutes:seconds e.g. 3:00:00 for 3 hours # minutes # days-hours SBATCH --time=<time> # MEMORY PER NODE # See above \"Specifying Memory Size\" for options SBATCH --mem=<size>G # e.g. --mem=100G for 100 GB of memory # WORKING DIRECTORY ENTRYPOINT # Specify the working directory for this job SBATCH --chdir=/gscratch/<group_name>/<net_id>/path/to/dir # Turn on email notifications SBATCH --mail-type=ALL SBATCH --mail-user=<your_email> # Export all environment variables to the batch job session SBATCH --export=all # Run the commands to run your program here # e.g. load modules, copy input.output files, run program, etc. <commands_to_run_your_program> "},{"title":"Multiple Node Batch Jobs","type":1,"pageTitle":"Scheduling Jobs","url":"docs/compute/scheduling-jobs#multiple-node-batch-jobs","content":"If your batch job is using multiple nodes, your program should also know how to use all the nodes (e.g. your program is an MPI program). The value given for --nodes must be less than or equal to the total number of nodes owned by your group. The value given for --ntasks-per-node should be either 28 for older mox nodes or 40 for newer nodes. Do not increase these values. You can decrease these values if your program is running out of memory on a node. Copy SBATCH --nodes=4 SBATCH --ntasks-per-node=28 # OR SBATCH --ntasks-per-node=40 "},{"title":"Self-Limiting Your Number of Running Jobs","type":1,"pageTitle":"Scheduling Jobs","url":"docs/compute/scheduling-jobs#self-limiting-your-number-of-running-jobs","content":"note This feature is not enabled on the ckpt partition At times you may wish to self-limit the number of jobs that will be run simultaneously in order to leave nodes in your group's partition for other group members. To achieve this, you can add SBATCH --qos=MaxJobs<n> where n is a number between 1 and 10 to tell the job scheduler to allow only n jobs running with the option --qos=MaxJobs<n>. However, any other jobs without this option set are not limited and jobs with a different value of n are gated separately. "},{"title":"Common Slurm Error Messages","type":1,"pageTitle":"Scheduling Jobs","url":"docs/compute/scheduling-jobs#common-slurm-error-messages","content":"slurmstepd: error: Exceeded job memory limit: your program uses more memory than you allotted during node creation and it has run out of memory. Get a node with more memory and try again.(ReqNodeNotAvail, UnavailableNodes:n[<node numbers list>]: your node will not expire (and might be running one of your jobs) before the next scheduled maintenance day. Either get a node with a shorter --time duration or wait until after the maintenance has been completed.Unable to allocate resources: Invalid account or account/partition combination specified: you used -p <group_name> -A <group_name> and you do not belong to that group. "},{"title":"Utility Commands","type":1,"pageTitle":"Scheduling Jobs","url":"docs/compute/scheduling-jobs#utility-commands","content":"With <net_id> as your UW NetID and <group_name> as your Hyak group partition name, and <job_id> as an individual job ID: sinfo is used to view information about mox nodes and partitions. Use sinfo -p <group_name> to view information about your group's partition or allocation.squeue is used to view information about jobs located in the scheduling queue. Use squeue -p <group_name> to view information about your group's nodes. Use squeue -u <net_id> to view your jobs.scancel is used to cancel jobs. Use scancel <job_id> to cancel a job with the given job ID, or use scancel -u <net_id> to cancel all of your jobs.sstat displays status information of a running job pertaining to CPU, Task, Node, Resident Set Size (RSS), and Virtual Memory (VM) statistics. Read the man page for a comprehensive list of format options. sacct displays information about completed jobs. Read the man page for a comprehensive list of format options.sreport generates reports about job usage and cluster utilization from Slurm accounting (sacct) data. For example, to get historical usage the group <group_name> in March 2020, use sreport cluster UserUtilizationByAccount Start=2020-03-01 End=2020-03-31 Accounts=<group_name>. "},{"title":"FOR ADVANCED USERS ONLY: salloc","type":1,"pageTitle":"Scheduling Jobs","url":"docs/compute/scheduling-jobs#for-advanced-users-only-salloc","content":"warning Do not use salloc unless you have a specific reason. To get nodes for interactive use: Copy salloc -N <num_nodes> -p <group_name> -A <group_name> --time=<time> --mem=<size>G When this command runs, you will have been allocated num_nodes nodes but you will still be on the mox login node. Use srun <command> to run commands on all allocated nodes. Use scontrol show hostnames to get the hostnames of your allocated nodes. Once you have the hostnames, you can ssh to them using ssh <hostname> and then use them for your work (e.g. Apache Spark, Hadoop, etc.) Example: Copy [linj66@mox2 ~]$ salloc -N 2 -p stf -A stf --time=5 --mem=5G salloc: Pending job allocation 2620960 salloc: job 2620960 queued and waiting for resources salloc: job 2620960 has been allocated resources salloc: Granted job allocation 2620960 salloc: Waiting for resource configuration salloc: Nodes n[2148-2149] are ready for job [linj66@mox2 ~]$ srun echo \"test\" test test [linj66@mox2 ~]$ scontrol show hostnames n2148 n2149 [linj66@mox2 ~]$ ssh n2148 Warning: Permanently added 'n2148,10.64.56.248' (ECDSA) to the list of known hosts. [linj66@n2148 ~]$ "},{"title":"Man Pages","type":1,"pageTitle":"Scheduling Jobs","url":"docs/compute/scheduling-jobs#man-pages","content":"All of these man pages can also be viewed on mox by running man <command>. sacctsallocsbatchscancelscontrolsinfosqueuesreportsrunsstat "},{"title":"Markdown Guide","type":0,"sectionRef":"#","url":"docs/contribute/markdown-guide","content":"","keywords":""},{"title":"Markdown Syntax","type":1,"pageTitle":"Markdown Guide","url":"docs/contribute/markdown-guide#markdown-syntax","content":"To serve as an example page when styling markdown based Docusaurus sites. "},{"title":"Headers","type":1,"pageTitle":"Markdown Guide","url":"docs/contribute/markdown-guide#headers","content":"H1 - Create the best documentation# "},{"title":"H2 - Create the best documentation","type":1,"pageTitle":"Markdown Guide","url":"docs/contribute/markdown-guide#h2---create-the-best-documentation","content":""},{"title":"H3 - Create the best documentation","type":1,"pageTitle":"Markdown Guide","url":"docs/contribute/markdown-guide#h3---create-the-best-documentation","content":"H4 - Create the best documentation# H5 - Create the best documentation# H6 - Create the best documentation#  "},{"title":"Emphasis","type":1,"pageTitle":"Markdown Guide","url":"docs/contribute/markdown-guide#emphasis","content":"Emphasis, aka italics, with asterisks or underscores. Strong emphasis, aka bold, with asterisks or underscores. Combined emphasis with asterisks and underscores. Strikethrough uses two tildes. Scratch this.  "},{"title":"Lists","type":1,"pageTitle":"Markdown Guide","url":"docs/contribute/markdown-guide#lists","content":"First ordered list itemAnother item â‹…â‹…* Unordered sub-list.Actual numbers don't matter, just that it's a number â‹…â‹…1. Ordered sub-listAnd another item. â‹…â‹…â‹…You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we'll use three here to also align the raw Markdown). â‹…â‹…â‹…To have a line break without a paragraph, you will need to use two trailing spaces.â‹…â‹… â‹…â‹…â‹…Note that this line is separate, but within the same paragraph.â‹…â‹… â‹…â‹…â‹…(This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.) Unordered list can use asterisks Or minuses Or pluses  "},{"title":"Links","type":1,"pageTitle":"Markdown Guide","url":"docs/contribute/markdown-guide#links","content":"I'm an inline-style link I'm an inline-style link with title I'm a reference-style link I'm a relative reference to a repository file You can use numbers for reference-style link definitions Or leave it empty and use the link text itself. URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or http://www.example.com and sometimes example.com (but not on Github, for example). Some text to show that the reference links can follow later.  "},{"title":"Images","type":1,"pageTitle":"Markdown Guide","url":"docs/contribute/markdown-guide#images","content":"Here's our logo (hover to see the title text): Inline-style:  Reference-style:   "},{"title":"Code","type":1,"pageTitle":"Markdown Guide","url":"docs/contribute/markdown-guide#code","content":"Copy var s = 'JavaScript syntax highlighting'; alert(s); Copy s = \"Python syntax highlighting\" print(s) Copy No language indicated, so no syntax highlighting. But let's throw in a <b>tag</b>. Copy function highlightMe() { console.log('This line can be highlighted!'); }  "},{"title":"Tables","type":1,"pageTitle":"Markdown Guide","url":"docs/contribute/markdown-guide#tables","content":"Colons can be used to align columns. Tables\tAre\tCoolcol 3 is\tright-aligned\t\\$1600 col 2 is\tcentered\t\\$12 zebra stripes\tare neat\t\\$1 There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don't need to make the raw Markdown line up prettily. You can also use inline Markdown. Markdown\tLess\tPrettyStill\trenders\tnicely 1\t2\t3  "},{"title":"Blockquotes","type":1,"pageTitle":"Markdown Guide","url":"docs/contribute/markdown-guide#blockquotes","content":"Blockquotes are very handy in email to emulate reply text. This line is part of the same quote. Quote break. This is a very long line that will still be quoted properly when it wraps. Oh boy let's keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can put Markdown into a blockquote.  "},{"title":"Inline HTML","type":1,"pageTitle":"Markdown Guide","url":"docs/contribute/markdown-guide#inline-html","content":"Definition list Is something people use sometimes. Markdown in HTML Does *not* work **very** well. Use HTML tags.  "},{"title":"Line Breaks","type":1,"pageTitle":"Markdown Guide","url":"docs/contribute/markdown-guide#line-breaks","content":"Here's a line for us to start with. This line is separated from the one above by two newlines, so it will be a separate paragraph. This line is also a separate paragraph, but... This line is only separated by a single newline, so it's a separate line in the same paragraph.  "},{"title":"Admonitions","type":1,"pageTitle":"Markdown Guide","url":"docs/contribute/markdown-guide#admonitions","content":"note This is a note tip This is a tip important This is important caution This is a caution warning This is a warning "},{"title":"Powered by MDX","type":0,"sectionRef":"#","url":"docs/contribute/mdx","content":"You can write JSX and use React components within your Markdown thanks to MDX. Docusaurus green and Facebook blue are my favorite colors. I can write Markdown alongside my JSX!","keywords":""},{"title":"Getting Set Up","type":0,"sectionRef":"#","url":"docs/setup","content":"Probably have something about how to register with UW RCC and getting Hyak and Lolo up and what not here.","keywords":""},{"title":"Join a Group","type":0,"sectionRef":"#","url":"docs/join-group","content":"","keywords":""},{"title":"How do you become a group owner?","type":1,"pageTitle":"Join a Group","url":"docs/join-group#how-do-you-become-a-group-owner","content":"Groups are tied to resources, your options are to contribute a node or have a dedicated lab storage space on a HYAK cluster. Once your group is created the group owner can add or remove users by their netIDs and those users will get access to those node(s) and / or associated storage. "},{"title":"How does a group owner add or remove a user?","type":1,"pageTitle":"Join a Group","url":"docs/join-group#how-does-a-group-owner-add-or-remove-a-user","content":"A group owner, usually the PI or designated staff (e.g., lab manager), should take the following steps: Log into groups.uw.eduClick \"My groups\" in the top menu barGo to u_hyak_mylab where mylab is your groups' nameClick \"Membership\" just underneath the top menu barA field appears to \"Add members\" by netID. Enter multiple netIDs one per line or separated by commas. NOTE: This is also how you remove members from your group when the time comes (under the \"Remove members\" field).Click \"Do it\" caution These netIDs now have access to your nodes and lab data on HYAK once they log into the cluster. "},{"title":"Archive","type":0,"sectionRef":"#","url":"docs/storage/archive","content":"","keywords":""},{"title":"What is LOLO Tape?","type":1,"pageTitle":"Archive","url":"docs/storage/archive#what-is-lolo-tape","content":"LOLO is the UW's archive solution, it is an LTO-8 or \"tape\" based platform. note LOLO costs $4 / TB / month. "},{"title":"How do I get LOLO capacity?","type":1,"pageTitle":"Archive","url":"docs/storage/archive#how-do-i-get-lolo-capacity","content":"Go to https://uwnetid.washington.edu/manage/Click the \"Computing Services\" link on the leftClick the \"Lolo Server\" check box in the \"Inactive Services\" section.Click the \"Subscribe >\" button at the bottom of the page.Read the notice and click the \"Finish\" button. "},{"title":"How to back up to LOLO?","type":1,"pageTitle":"Archive","url":"docs/storage/archive#how-to-back-up-to-lolo","content":"TODO "},{"title":"Google Drive","type":1,"pageTitle":"Archive","url":"docs/storage/archive#google-drive","content":"The UW has a relationship with Google for cloud services (e.g., Gmail, Google Drive). Google Drive has a reputation for \"unlimited\" data storage. It's possible you can use this as one place to store your data but we leave it to the user to perform their own due diligence on the implications of this. Some labs at the UW make use of Google Drive in this manner so we thought we'd make note of it here but we provide no support for it. "},{"title":"3-2-1 Policy","type":0,"sectionRef":"#","url":"docs/storage/best-practice","content":"Storage on every HYAK cluster is physically separate. It is best practice on every supercomputer that storage live on its own and is high-performance to handle the bandwidth I/O and read/write operations required by so many compute nodes attached to it. These are typically parallel file systems (e.g., GPFS, Lustre, BeeGFS). This storage system is then mounted (i.e., accessible) from every compute node of the cluster. Each HYAK cluster (e.g., klone, mox) has its own separate.","keywords":""},{"title":"Start Here","type":0,"sectionRef":"#","url":"docs/storage/data","content":"","keywords":""},{"title":"What is storage for a supercomputer?","type":1,"pageTitle":"Start Here","url":"docs/storage/data#what-is-storage-for-a-supercomputer","content":"Storage on every HYAK cluster is physically separate. It is best practice on every supercomputer that storage live as its own infrastructure to be high-performance and able to handle the bandwidth I/O and read/write operations required by so many compute nodes attached to it. These are typically parallel file systems (e.g., GPFS, Lustre, BeeGFS). Storage systems are mounted (i.e., accessible) from every compute node of the cluster. Each HYAK cluster (e.g., klone, mox) has its own separate parallel file system. The storage attached to each HYAK cluster has its own policies, hierachy, etc. Please refer to their respective pages for more information. warning Cluster storage is not backed up! While our storage systems have a track record of stability, it is important to note that STORAGE IS NOT BACKED UP by default. It is the responsibility of the user that in the event of an incident you have a place and plan to restore their data. We provide a complementary archive service that is appropriate for this and other solutions exist. "},{"title":"3-2-1 Policy","type":1,"pageTitle":"Start Here","url":"docs/storage/data#3-2-1-policy","content":"Your data is precious, in some cases completely irreplacable. However, we have a lot of tip 3-2-1 is not a HYAK thing, it's a general IT best practice. "},{"title":"Storage on KLONE","type":0,"sectionRef":"#","url":"docs/storage/klone","content":"TODO","keywords":""},{"title":"Storage on MOX","type":0,"sectionRef":"#","url":"docs/storage/mox","content":"","keywords":""},{"title":"User Home Directory","type":1,"pageTitle":"Storage on MOX","url":"docs/storage/mox#user-home-directory","content":"Each users' home directory is located at the folder path /gscratch/home/netID where netID is your UW netID. You are placed here by default when you log into mox. You can always refer to it using the usual Linux shortcuts of $HOME or ~. note Your home directory quota is 10 GB or 250,000 files. You can check your live home directory usage using the following command. Copy mmlsquota --block-size G gscratch:home Ideally you only keep personal code bases or smaller data sets here. This quota can not be changed, if you need more data one of the other storage spots on gscratch are better suited. "},{"title":"Group or Lab Directories","type":1,"pageTitle":"Storage on MOX","url":"docs/storage/mox#group-or-lab-directories","content":"If you run the groups command on mox you'll see what groups you are a member of. For example, one of my groups is hyak-stf, which means I'm a member of the \"stf\" group (i.e., the Research Computing Club). Whatever groups you are seeing here you can access your lab storage at /gscratch/mylab/ where mylab is any group you're a member of. In this example that means I have access to the /gscratch/stf/ and only members of the hyak-stf group have access to this folder. Your lab gets 500 GB per node that your group has contributed to mox (or 2 TB per node in the case of a GPU node). tip Your lab quota can be increased for $10 / TB / month. Your lab storage quota can be increased (or decreased) in 1 TB granularity and adjusted on a month-to-month basis as your needs require. If you hit file limits, email us and we can increase those limits for no additional cost. important Check group quotas and current use by looking at the /gscratch/mylab/usage_report.txt file. "},{"title":"Scrubbed","type":1,"pageTitle":"Storage on MOX","url":"docs/storage/mox#scrubbed","content":"If you need space but only temporarily (i.e., less than 1 month) then you can make use of the scrubbed folder. The scrubbed folder lives at /gscratch/scrubbed/ and anything underneath this folder is a free-for-all space. You can create a folder for yourself and do whatever you need. Please note it's completely open caution Auto-delete: caution Privacy: "},{"title":"Data Transfer","type":0,"sectionRef":"#","url":"docs/storage/transfer","content":"Storage on every HYAK cluster is physically separate. It is best practice on every supercomputer that storage live on its own and is high-performance to handle the bandwidth I/O and read/write operations required by so many compute nodes attached to it. These are typically parallel file systems (e.g., GPFS, Lustre, BeeGFS). This storage system is then mounted (i.e., accessible) from every compute node of the cluster. Each HYAK cluster (e.g., klone, mox) has its own separate.","keywords":""},{"title":"Jupyter Notebooks","type":0,"sectionRef":"#","url":"docs/tools/jupyter","content":"TODO","keywords":""},{"title":"Modules","type":0,"sectionRef":"#","url":"docs/tools/modules","content":"Modules","keywords":""},{"title":"Containers","type":0,"sectionRef":"#","url":"docs/tools/containers","content":"","keywords":""},{"title":"Interactive Nodes","type":1,"pageTitle":"Containers","url":"docs/tools/containers#interactive-nodes","content":"There are two types of interactive nodes. Compute nodes run computations but cannot connect to the internet. Build nodes are compute nodes that can connect to the Internet to get files and install packages from outside the mox ecosystem. "},{"title":"Obtaining Interactive Nodes","type":1,"pageTitle":"Containers","url":"docs/tools/containers#obtaining-interactive-nodes","content":"To get an interactive compute node with <size> GB of memory in your group partition called <group_name> for <time> hours, use: Copy srun -p <group_name> --time=<time> --mem=<size>G --pty /bin/bash Common acceptable time formats include hours:minutes:seconds, days-hours, and minutes. Example: Copy [linj66@mox2 ~]$ srun -p stf --time=1:00:00 --mem=20G --pty /bin/bash [linj66@n2148 ~]$   To get an interactive compute node with <num_cores> cores, use: Copy srun -p <group_name> -A <group_name> --nodes=1 \\ --ntasks-per-node=<num_cores> --time=<time> \\ --mem=<size>G --pty /bin/bash  To get multiple interactive compute nodes with <num_nodes> as the number of nodes and <cores_per_node> as the number of cores, use: Copy srun -p <group_name> -A <group_name> --nodes=<num_nodes> \\ --ntasks-per-node=<cores_per_node> --time=<time> \\ --mem=<size>G --pty /bin/bash When this command runs, you will automatically enter into a session in one of the allocated nodes. To view the names of all your allocated nodes, use scontrol show hostnames. important If you are using an interactive node to run a parallel application such as Python multiprocessing, MPI, OpenMP etc. then the number given for the --ntasks-per-node option must match the number of processes used by your application.  If your group has an interactive node, use the option -p <group_name>-int like so: Copy srun -p <group_name>-int -A <group_name> --time=<time> --mem=<size>G --pty /bin/bash note --pty /bin/bash must be the last option given in above commandIf you do not obtain a build node with the specified --mem value, try smaller memory values For more details, read the srun man page. "},{"title":"Build Nodes","type":1,"pageTitle":"Containers","url":"docs/tools/containers#build-nodes","content":"Build nodes are allocated from the build group partition. To obtain a build node, execute srun with the option -p build. "},{"title":"Specifying Memory Size","type":1,"pageTitle":"Containers","url":"docs/tools/containers#specifying-memory-size","content":"It is important to use the --mem option to specify the memory allocation; otherwise the Slurm scheduler limits the memory allocation to a default value which is usually quite low. The value given to --mem should be smaller than the memory of the node as the operating system needs some. For 64GB nodes, use --mem=58GFor 128GB nodes, use --mem=120GFor 192GB nodes, use --mem=185GFor 256GB nodes, use --mem=248GFor 384GB nodes, use --mem=374GFor 512GB nodes, use --mem=500GFor 768GB nodes, use --mem=752GFor the knl nodes, use --mem=200G "},{"title":"Slurm Environment Variables","type":1,"pageTitle":"Containers","url":"docs/tools/containers#slurm-environment-variables","content":"When a job scheduled by Slurm begins, it needs to about how it was scheduled, what its working directory is, who submitted the job, the number of nodes and cores allocated to it, etc. This information is passed to Slurm via environment variables. Additionally, these environment variables are also used as default values by programs like mpirun. To view a node's Slurm environment variables, use export | grep SLURM. A comprehensive list of the environment variables Slurm sets for each job can be found at the end of the sbatch man page. "},{"title":"Batch Jobs","type":1,"pageTitle":"Containers","url":"docs/tools/containers#batch-jobs","content":""},{"title":"Single Node Batch Jobs","type":1,"pageTitle":"Containers","url":"docs/tools/containers#single-node-batch-jobs","content":"Below is a slurm script template. Submit a batch job from the mox login node by calling sbatch <script_name>.slurm. <script_name>.slurm Copy !/bin/bash # JOB NAME SBATCH --job-name=<your_job_name> # ALLOCATION DEFINITION # The account and partition options should be the same # except in a few cases (e.g. ckpt queue, genpool queue) SBATCH --account=<group_name> SBATCH --partition=<group_name> # RESOURCES SBATCH --nodes=<num_nodes> # total number of nodes allocated SBATCH --ntasks-per-node=<cores_per_node> # cores per node # WALL TIME # Do not specify a wall time significantly more than your job needs # Common acceptable time formats: # hours:minutes:seconds e.g. 3:00:00 for 3 hours # minutes # days-hours SBATCH --time=<time> # MEMORY PER NODE # See above \"Specifying Memory Size\" for options SBATCH --mem=<size>G # e.g. --mem=100G for 100 GB of memory # WORKING DIRECTORY ENTRYPOINT # Specify the working directory for this job SBATCH --chdir=/gscratch/<group_name>/<net_id>/path/to/dir # Turn on email notifications SBATCH --mail-type=ALL SBATCH --mail-user=<your_email> # Export all environment variables to the batch job session SBATCH --export=all # Run the commands to run your program here # e.g. load modules, copy input.output files, run program, etc. <commands_to_run_your_program> "},{"title":"Multiple Node Batch Jobs","type":1,"pageTitle":"Containers","url":"docs/tools/containers#multiple-node-batch-jobs","content":"If your batch job is using multiple nodes, your program should also know how to use all the nodes (e.g. your program is an MPI program). The value given for --nodes must be less than or equal to the total number of nodes owned by your group. The value given for --ntasks-per-node should be either 28 for older mox nodes or 40 for newer nodes. Do not increase these values. You can decrease these values if your program is running out of memory on a node. Copy SBATCH --nodes=4 SBATCH --ntasks-per-node=28 # OR SBATCH --ntasks-per-node=40 "},{"title":"Self-Limiting Your Number of Running Jobs","type":1,"pageTitle":"Containers","url":"docs/tools/containers#self-limiting-your-number-of-running-jobs","content":"note This feature is not enabled on the ckpt partition At times you may wish to self-limit the number of jobs that will be run simultaneously in order to leave nodes in your group's partition for other group members. To achieve this, you can add SBATCH --qos=MaxJobs<n> where n is a number between 1 and 10 to tell the job scheduler to allow only n jobs running with the option --qos=MaxJobs<n>. However, any other jobs without this option set are not limited and jobs with a different value of n are gated separately. "},{"title":"Common Slurm Error Messages","type":1,"pageTitle":"Containers","url":"docs/tools/containers#common-slurm-error-messages","content":"slurmstepd: error: Exceeded job memory limit: your program uses more memory than you allotted during node creation and it has run out of memory. Get a node with more memory and try again.(ReqNodeNotAvail, UnavailableNodes:n[<node numbers list>]: your node will not expire (and might be running one of your jobs) before the next scheduled maintenance day. Either get a node with a shorter --time duration or wait until after the maintenance has been completed.Unable to allocate resources: Invalid account or account/partition combination specified: you used -p <group_name> -A <group_name> and you do not belong to that group. "},{"title":"Utility Commands","type":1,"pageTitle":"Containers","url":"docs/tools/containers#utility-commands","content":"With <net_id> as your UW NetID and <group_name> as your Hyak group partition name, and <job_id> as an individual job ID: sinfo is used to view information about mox nodes and partitions. Use sinfo -p <group_name> to view information about your group's partition or allocation.squeue is used to view information about jobs located in the scheduling queue. Use squeue -p <group_name> to view information about your group's nodes. Use squeue -u <net_id> to view your jobs.scancel is used to cancel jobs. Use scancel <job_id> to cancel a job with the given job ID, or use scancel -u <net_id> to cancel all of your jobs.sstat displays status information of a running job pertaining to CPU, Task, Node, Resident Set Size (RSS), and Virtual Memory (VM) statistics. Read the man page for a comprehensive list of format options. sacct displays information about completed jobs. Read the man page for a comprehensive list of format options.sreport generates reports about job usage and cluster utilization from Slurm accounting (sacct) data. For example, to get historical usage the group <group_name> in March 2020, use sreport cluster UserUtilizationByAccount Start=2020-03-01 End=2020-03-31 Accounts=<group_name>. "},{"title":"FOR ADVANCED USERS ONLY: salloc","type":1,"pageTitle":"Containers","url":"docs/tools/containers#for-advanced-users-only-salloc","content":"warning Do not use salloc unless you have a specific reason. To get nodes for interactive use: Copy salloc -N <num_nodes> -p <group_name> -A <group_name> --time=<time> --mem=<size>G When this command runs, you will have been allocated num_nodes nodes but you will still be on the mox login node. Use srun <command> to run commands on all allocated nodes. Use scontrol show hostnames to get the hostnames of your allocated nodes. Once you have the hostnames, you can ssh to them using ssh <hostname> and then use them for your work (e.g. Apache Spark, Hadoop, etc.) Example: Copy [linj66@mox2 ~]$ salloc -N 2 -p stf -A stf --time=5 --mem=5G salloc: Pending job allocation 2620960 salloc: job 2620960 queued and waiting for resources salloc: job 2620960 has been allocated resources salloc: Granted job allocation 2620960 salloc: Waiting for resource configuration salloc: Nodes n[2148-2149] are ready for job [linj66@mox2 ~]$ srun echo \"test\" test test [linj66@mox2 ~]$ scontrol show hostnames n2148 n2149 [linj66@mox2 ~]$ ssh n2148 Warning: Permanently added 'n2148,10.64.56.248' (ECDSA) to the list of known hosts. [linj66@n2148 ~]$ "},{"title":"Man Pages","type":1,"pageTitle":"Containers","url":"docs/tools/containers#man-pages","content":"All of these man pages can also be viewed on mox by running man <command>. sacctsallocsbatchscancelscontrolsinfosqueuesreportsrunsstat "},{"title":"Python","type":0,"sectionRef":"#","url":"docs/tools/python","content":"","keywords":""},{"title":"Interactive Nodes","type":1,"pageTitle":"Python","url":"docs/tools/python#interactive-nodes","content":"There are two types of interactive nodes. Compute nodes run computations but cannot connect to the internet. Build nodes are compute nodes that can connect to the Internet to get files and install packages from outside the mox ecosystem. "},{"title":"Obtaining Interactive Nodes","type":1,"pageTitle":"Python","url":"docs/tools/python#obtaining-interactive-nodes","content":"To get an interactive compute node with <size> GB of memory in your group partition called <group_name> for <time> hours, use: Copy srun -p <group_name> --time=<time> --mem=<size>G --pty /bin/bash Common acceptable time formats include hours:minutes:seconds, days-hours, and minutes. Example: Copy [linj66@mox2 ~]$ srun -p stf --time=1:00:00 --mem=20G --pty /bin/bash [linj66@n2148 ~]$   To get an interactive compute node with <num_cores> cores, use: Copy srun -p <group_name> -A <group_name> --nodes=1 \\ --ntasks-per-node=<num_cores> --time=<time> \\ --mem=<size>G --pty /bin/bash  To get multiple interactive compute nodes with <num_nodes> as the number of nodes and <cores_per_node> as the number of cores, use: Copy srun -p <group_name> -A <group_name> --nodes=<num_nodes> \\ --ntasks-per-node=<cores_per_node> --time=<time> \\ --mem=<size>G --pty /bin/bash When this command runs, you will automatically enter into a session in one of the allocated nodes. To view the names of all your allocated nodes, use scontrol show hostnames. important If you are using an interactive node to run a parallel application such as Python multiprocessing, MPI, OpenMP etc. then the number given for the --ntasks-per-node option must match the number of processes used by your application.  If your group has an interactive node, use the option -p <group_name>-int like so: Copy srun -p <group_name>-int -A <group_name> --time=<time> --mem=<size>G --pty /bin/bash note --pty /bin/bash must be the last option given in above commandIf you do not obtain a build node with the specified --mem value, try smaller memory values For more details, read the srun man page. "},{"title":"Build Nodes","type":1,"pageTitle":"Python","url":"docs/tools/python#build-nodes","content":"Build nodes are allocated from the build group partition. To obtain a build node, execute srun with the option -p build. "},{"title":"Specifying Memory Size","type":1,"pageTitle":"Python","url":"docs/tools/python#specifying-memory-size","content":"It is important to use the --mem option to specify the memory allocation; otherwise the Slurm scheduler limits the memory allocation to a default value which is usually quite low. The value given to --mem should be smaller than the memory of the node as the operating system needs some. For 64GB nodes, use --mem=58GFor 128GB nodes, use --mem=120GFor 192GB nodes, use --mem=185GFor 256GB nodes, use --mem=248GFor 384GB nodes, use --mem=374GFor 512GB nodes, use --mem=500GFor 768GB nodes, use --mem=752GFor the knl nodes, use --mem=200G "},{"title":"Slurm Environment Variables","type":1,"pageTitle":"Python","url":"docs/tools/python#slurm-environment-variables","content":"When a job scheduled by Slurm begins, it needs to about how it was scheduled, what its working directory is, who submitted the job, the number of nodes and cores allocated to it, etc. This information is passed to Slurm via environment variables. Additionally, these environment variables are also used as default values by programs like mpirun. To view a node's Slurm environment variables, use export | grep SLURM. A comprehensive list of the environment variables Slurm sets for each job can be found at the end of the sbatch man page. "},{"title":"Batch Jobs","type":1,"pageTitle":"Python","url":"docs/tools/python#batch-jobs","content":""},{"title":"Single Node Batch Jobs","type":1,"pageTitle":"Python","url":"docs/tools/python#single-node-batch-jobs","content":"Below is a slurm script template. Submit a batch job from the mox login node by calling sbatch <script_name>.slurm. <script_name>.slurm Copy !/bin/bash # JOB NAME SBATCH --job-name=<your_job_name> # ALLOCATION DEFINITION # The account and partition options should be the same # except in a few cases (e.g. ckpt queue, genpool queue) SBATCH --account=<group_name> SBATCH --partition=<group_name> # RESOURCES SBATCH --nodes=<num_nodes> # total number of nodes allocated SBATCH --ntasks-per-node=<cores_per_node> # cores per node # WALL TIME # Do not specify a wall time significantly more than your job needs # Common acceptable time formats: # hours:minutes:seconds e.g. 3:00:00 for 3 hours # minutes # days-hours SBATCH --time=<time> # MEMORY PER NODE # See above \"Specifying Memory Size\" for options SBATCH --mem=<size>G # e.g. --mem=100G for 100 GB of memory # WORKING DIRECTORY ENTRYPOINT # Specify the working directory for this job SBATCH --chdir=/gscratch/<group_name>/<net_id>/path/to/dir # Turn on email notifications SBATCH --mail-type=ALL SBATCH --mail-user=<your_email> # Export all environment variables to the batch job session SBATCH --export=all # Run the commands to run your program here # e.g. load modules, copy input.output files, run program, etc. <commands_to_run_your_program> "},{"title":"Multiple Node Batch Jobs","type":1,"pageTitle":"Python","url":"docs/tools/python#multiple-node-batch-jobs","content":"If your batch job is using multiple nodes, your program should also know how to use all the nodes (e.g. your program is an MPI program). The value given for --nodes must be less than or equal to the total number of nodes owned by your group. The value given for --ntasks-per-node should be either 28 for older mox nodes or 40 for newer nodes. Do not increase these values. You can decrease these values if your program is running out of memory on a node. Copy SBATCH --nodes=4 SBATCH --ntasks-per-node=28 # OR SBATCH --ntasks-per-node=40 "},{"title":"Self-Limiting Your Number of Running Jobs","type":1,"pageTitle":"Python","url":"docs/tools/python#self-limiting-your-number-of-running-jobs","content":"note This feature is not enabled on the ckpt partition At times you may wish to self-limit the number of jobs that will be run simultaneously in order to leave nodes in your group's partition for other group members. To achieve this, you can add SBATCH --qos=MaxJobs<n> where n is a number between 1 and 10 to tell the job scheduler to allow only n jobs running with the option --qos=MaxJobs<n>. However, any other jobs without this option set are not limited and jobs with a different value of n are gated separately. "},{"title":"Common Slurm Error Messages","type":1,"pageTitle":"Python","url":"docs/tools/python#common-slurm-error-messages","content":"slurmstepd: error: Exceeded job memory limit: your program uses more memory than you allotted during node creation and it has run out of memory. Get a node with more memory and try again.(ReqNodeNotAvail, UnavailableNodes:n[<node numbers list>]: your node will not expire (and might be running one of your jobs) before the next scheduled maintenance day. Either get a node with a shorter --time duration or wait until after the maintenance has been completed.Unable to allocate resources: Invalid account or account/partition combination specified: you used -p <group_name> -A <group_name> and you do not belong to that group. "},{"title":"Utility Commands","type":1,"pageTitle":"Python","url":"docs/tools/python#utility-commands","content":"With <net_id> as your UW NetID and <group_name> as your Hyak group partition name, and <job_id> as an individual job ID: sinfo is used to view information about mox nodes and partitions. Use sinfo -p <group_name> to view information about your group's partition or allocation.squeue is used to view information about jobs located in the scheduling queue. Use squeue -p <group_name> to view information about your group's nodes. Use squeue -u <net_id> to view your jobs.scancel is used to cancel jobs. Use scancel <job_id> to cancel a job with the given job ID, or use scancel -u <net_id> to cancel all of your jobs.sstat displays status information of a running job pertaining to CPU, Task, Node, Resident Set Size (RSS), and Virtual Memory (VM) statistics. Read the man page for a comprehensive list of format options. sacct displays information about completed jobs. Read the man page for a comprehensive list of format options.sreport generates reports about job usage and cluster utilization from Slurm accounting (sacct) data. For example, to get historical usage the group <group_name> in March 2020, use sreport cluster UserUtilizationByAccount Start=2020-03-01 End=2020-03-31 Accounts=<group_name>. "},{"title":"FOR ADVANCED USERS ONLY: salloc","type":1,"pageTitle":"Python","url":"docs/tools/python#for-advanced-users-only-salloc","content":"warning Do not use salloc unless you have a specific reason. To get nodes for interactive use: Copy salloc -N <num_nodes> -p <group_name> -A <group_name> --time=<time> --mem=<size>G When this command runs, you will have been allocated num_nodes nodes but you will still be on the mox login node. Use srun <command> to run commands on all allocated nodes. Use scontrol show hostnames to get the hostnames of your allocated nodes. Once you have the hostnames, you can ssh to them using ssh <hostname> and then use them for your work (e.g. Apache Spark, Hadoop, etc.) Example: Copy [linj66@mox2 ~]$ salloc -N 2 -p stf -A stf --time=5 --mem=5G salloc: Pending job allocation 2620960 salloc: job 2620960 queued and waiting for resources salloc: job 2620960 has been allocated resources salloc: Granted job allocation 2620960 salloc: Waiting for resource configuration salloc: Nodes n[2148-2149] are ready for job [linj66@mox2 ~]$ srun echo \"test\" test test [linj66@mox2 ~]$ scontrol show hostnames n2148 n2149 [linj66@mox2 ~]$ ssh n2148 Warning: Permanently added 'n2148,10.64.56.248' (ECDSA) to the list of known hosts. [linj66@n2148 ~]$ "},{"title":"Man Pages","type":1,"pageTitle":"Python","url":"docs/tools/python#man-pages","content":"All of these man pages can also be viewed on mox by running man <command>. sacctsallocsbatchscancelscontrolsinfosqueuesreportsrunsstat "},{"title":"R and Rstudio","type":0,"sectionRef":"#","url":"docs/tools/r","content":"TODO","keywords":""},{"title":"Tutorial","type":0,"sectionRef":"#","url":"docs/tutorial","content":"Probably put something about how to run a simple HYAK job or something here.","keywords":""}]